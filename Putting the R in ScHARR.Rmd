---
title: \vspace{3.5in} "Putting the R in ScHARR"
author: "Robert Smith"
date: "`r format(Sys.time(), '%d. %B %Y')`"
output:
  
  pdf_document: default
  word_document: default
  html_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage 

\tableofcontents

\newpage 

## Introduction to R
This series of short courses are designed to equip the participant with a basic set of tools to undertake research using R. The aim is to create a strong foundation on which participants can build skills and knowledge specific to their research and consultancy objectives. The course makes use of the authors' experiences (many of which were frustrating) of working with R for data-science and statistical analysis. However there are many other resources available, and we would particularly recommend the freely available content at *[R for Data Science](https://r4ds.had.co.nz/)* as a good place to recap the materials taught in this course. The hard copy of Hadley Wickham and Garrett Grolemund's book of the same name (and content) is available at *[Amazon.com](https://r4ds.had.co.nz/)*. Alternatively, a user guide is available on the CRAN R-Project website [here](https://cran.r-project.org/doc/manuals/r-release/R-intro.html), although the author finds this less easy to follow than Hadley Wickham's book described above. Further details of where to go to answer more specific questions are provided throughout the course.

Requirements: It is assumed that all participants on the course have their own laptop, and have previously used software such as Excel or SPSS. Some basic understanding of statistics and mathematics is required (e.g. mean, median, minimum, maximum).


## Who we are:

*[Robert Smith](https://www.linkedin.com/in/robert-smith-53b28438/)* is a PhD Candidate at ScHARR, funded by the Wellcome Trust Doctoral Training Centre in Public Health Economics and Decision Science. His focus is on the methods used to estimate the costs and benefits of public health interventions, with a specific interest in microsimulation modelling (done in R). He has become increasingly intersted in the use of R-Markdown and R-Shiny to make research more transparent and to aid decision makers. While doing his PhD, Robert has been involved in projects with the WHO, Parkrun and Western Park Sports Medicine.

Paul Schneider ...

Sarah Bates ...

\newpage

### Course 1 Aims:
By the end of the 1 day short course, the attendee should be able to:

* Install and navigate R Studio. Set working directory.
* Understand the types of objects and basic operations in R.
* Read in data from csv and excel files.
* Summarise data. 
* Perform basic regression analysis on data.
* Create basic plots and graphs.
* Use an 'if' function
* Create a loop
* Know where to find further information (StatsExchange/Google).

### Course 2 Aims:
By the end of the 1 day short course, the attendee should be able to:

* Create beautiful graphs using ggplot.
* Use the 'apply()' function to improve run-time.
* Create a custom function.
* Know where to find further information (StatsExchange/Google).

### Course 3 Aims
By the end of 1 day short course, the attendee should also be able to:

* Understand the strengths and limitations of R for HTA.
* Create a markov model from scratch given known parameters.
* Create a microsimulation model to incorporate hetrogeneity between groups.
* Understand the importance of tranparency of coding. In particular commenting.

### Course 4 Aims
By the end of the 1 day short course, the attendee should be able to:

* Understand the benefits and limitations of R-Shiny.
* Have a basic understanding of the principles behind R-Shiny.
* Create an R-Shiny application from scratch.
* Integrate beautiful plots into R-Shiny.
* Develop a user interface for an existing complex model in R-Shiny.

### Course 5 Aims
By the end of the 1 day short course, the attendee should be able to:

* Understand the strengths and limitations of R-Markdown.
* Create replicatable HTML, Word and PDF documents using R-Markdown.
* Include chunks of code, graphs, references and biblographies, links to websites and pictures.
* Change replicate analysis for new or updated datasets, or create templates for routine data.
* Create markdown presentations.

\newpage

\vspace{3.5in} 
# Course 1

\newpage

## Install and navigate R Studio.

R is a free software environment for statistical analysis and data science. It is a collaborative effort started by Robert Gentleman and Ross Ihaka in New Zealand, but now made up of hundreds of people. R is made freely available by the Comprehensive R archive Network (CRAN), in the UK it can be downloaded through the University of Bristol [here](https://www.stats.bris.ac.uk/R/). 

Downloading R gives you the basic software environment, but an incredibly popular add-on called 'RStudio' is required to follow this course. You should download the free 'RStudio Desktop Open Source Licence' version for the laptop you will be attending the course with from [RStudio.com](https://www.rstudio.com/products/rstudio/#Desktop).

If you have time before the course, it would be hugely beneficial to get familiar with RStudio.


**Objectives:**

> Download R from <https://www.stats.bris.ac.uk/R/>.  
> Download RStudio from <https://www.rstudio.com/products/rstudio/#Desktop>.

## Basics


```{r,echo=TRUE}
# 1. basic basics
1 + 1

12/4

4^2 

```

### Objects Basics

```{r,echo=TRUE}

# objects basics
x = 3
y = 5
x + y
 
x = 4
x + y
  
z = x + y
z


```

### Manipulations
```{r,echo=TRUE}

 
x.2 = x
x.2

x.2 = x.2 + 1 
x.2 
x
```

### More complex objects

```{r,echo=TRUE}

height = c(1.72,1.78,1.65,1.90) # 1:4
height

weight = c(68,75,55,79)
weight

first_name = c("Alice","Bob","Harry","Jane")
first_name
#first_name + 1 # error

df = data.frame(height,weight,first_name)
df

df$bmi = df$weight / df$height^2 
df
```

### More complex objects
```{r,echo=TRUE}

# index
x
x[1]
x[2]
#x[2,2] #error
x[c(1,2)]
x[1:4]

df

df$height
df[1] # error   ## actually this isn't an error for me :)
df[,1]
df[2,]

df$height[2]
df[2,1]

df$height[2] - df$height[1]
```

### Evaluations
```{r,echo=TRUE}

# evaluations
4 > 2
4 > 5
4 == 3
4 != 3
"x" == "x"
```

### Subsetting
```{r,echo=TRUE}

# subsetting
df
min_height = df$height >= 1.75
min_height

df.at_least_175 = df[min_height,]
df.at_least_175


smaller = df$height < 1.75
df[smaller,]
df[!min_height,]

show_men = df$first_name %in% c("Harry","Bob")
df[show_men,]

# which(df$weight > 70)
# df[which(df$weight > 70),]
```


### Exercises

**Exercise 1**

a) Calculate the following:

5*10
20/3

b) Calculate x where a = 20 b = 9, c = 5, d = 1.2
*you are only allowed to type each number once*

$x = 4b + 7c + 3d$

$x = \frac{8b + 4c -12d}{a}$



${12\times(a+b)}\over {x}$

**Exercise 2**

a) Create a dataframe for five individuals (Andrew, Betty, Carl, Diane and Elisa) who are aged (62,80,24,40,56) and have gender (male, female, male,female, female). 

b) Use evaluations and subsetting to find the characteristics of the individual who can claim their free bus pass (age 65+).

c) Create a variable in the dataframe called life expectancy, set this to 83 for females and 80 for males.

d) Create another variable called lyr (life years remaining) which is the number of years to life expectancy for each individual.

## Understanding R. 

### Basic functions
Functions can be applied to make data manipulation easier. Many functions are included in baseR. For example mean. Mean returns the arithmetic mean of a vector of numbers. We can find out more about mean by entering ?mean.

```{r,echo=TRUE}
# find out more about mean
?mean

# create a vector of numbers
some_numbers = c(10,12,13,13,14,18,20)

# find the arithmetic mean of the numbers
average_value = mean(some_numbers)

#return the numbers
average_value
```

Other functions are more complex, requiring multiple inputs. For example **round** requires two inputs:
      x)   a value or multiple values
 digits)   the number of digits to round to. 

```{r,echo=TRUE}
# find more information about round
?round

# Rounding 5.7 to 0 digits gives 6.
round(x = 5.7,digits = 0)

# Rounding our average value to 2 digits gives 14.29.
round(average_value,2)

# We can do the same for multiple values
round(c(12.25,15.63,14.42),1)

```

Another useful function is sequence:

This requires the number to start from (*from*), the number to finish at (*to*), and the interval between numbers (*by*) in the sequence. Alternatively, instead of *by* the length of the sequence can be set using *length.out*.

```{r,echo=TRUE}
# find out more about sequence
?seq

# create a sequence of odds from 1 to 21.
seq(from = 1, to = 21, by = 2)

# create a sequence of length 10 from 1 to 21
seq(from = 1, to = 21, length.out = 10)
```

### Attributes
```{r,echo=TRUE}

# attributes
df
names(df)
#rownames(df) = c("row 1","row 2","row3") # error
rownames(df) = c("row 1","row 2","row3","row 4")
df

x
length(x)


str(df)
dim(df)

```

### Classes

```{r,echo=TRUE}

# classes
class(x)
class("this is a sentence")
class(df)

# matrix(1:9,ncol=3,nrow=3)

# the list
My_list = list(my_df = df,
               a_vector = x,
               another_one = y,
               some_text = c("foo","bar"))
My_list

My_list$a_vector

My_list$my_df

My_list[[1]]

My_list[[1]]$height

str(My_list)

# NA, Nan, Inf

```

### Environment
```{r,echo=TRUE}
# enviroment & wd
ls()
rm("y")
ls()
# attach(...)
rm(list=ls())
ls()
```

### If Statements

### Loops
There are numerous different ways to create loops, we are going to look at the simplist, the **for** loop which executes the command for each number given. 
```{r echo=TRUE}

 # Loop printing 1 to 10

for(i in 1:10) { # for each value of i from 1 to 10.
  print(i)       # print the value of i
}                # close the loop

```

We can also create an object, in this case a vector with the numbers we would like to loop through:

```{r echo=TRUE}

# create an object of odds
odds <- c(1,3,5,7,9)
 
# Loop printing all the values in the odds vector.
for(i in odds) { # for each value of i in the odds vector.
  print(i)       # print the value of i
}                # close the loop

```

If we create a vector, *ourdata*,  beforehand we can fill it with the output from each iteration of the loop. This is particularly useful if we want to record the output of a simulation.

```{r echo=TRUE}

#create an vector of empty data
ourdata <- vector(mode = "numeric",length = 10)
 
# Fill our vector with values
for(i in 1:length(ourdata)) { # for each value of i in our data object.
  ourdata[i] <- i             # print the value of i
}                             # close the loop

print(ourdata)                # print the vector

```

### Custom Function

```{r,echo=TRUE}
# my function
C_F_converter = function(x,c_to_f = T){
  if(c_to_f){
    res = x * 9/5 + 32 
  } else {
    res = (x - 32) * 5/9
  }
  return(res)
}

C_F_converter(22,c_to_f = T)
```

### Packages

Creating all your functions from scratch is a lot of work, where others have previously created the same functions, why reinvent the wheel. Instead we can stand on the shoulders of others by downloading 'packages'. Importantly though, we must understand what the functions within these packages are doing!

## Doing Research in R

### Importing Data

In almost every case, you will want to import some data to analyse. This data will come in a variety of formats. R studio has a nice feature in Environment>Import_Dataset which enables you to select the file you wish to download (similar to STATA) from your computer. The data is then imported into R and the code available in the console.

It is possible to import files in the following formats:

|  Type  | Suffix     | 
|--------|:----------:|
| R      |.R          |
| CSV    |.csv        |
| Excel  |.xls/.xlsx  |
| SPSS   |.spv        |
| Stata  |.dta        |


Alternatively packages can be installed to import data in almost any format. For example the readr package can read in spreadsheets from text files or tab delimited files.


#### CSV
We can import the file using the full path with the file name and suffix included such as below:

```{r,echo=TRUE,eval=FALSE}
read.csv("C:/Users/Robert/Google Drive/MyProject/Data/rawdata.csv", header=FALSE)
```

#### Setting Working Directory
Or, if we know that we are going to be downloading a lot of files from one folder we can set a working directory. The working directory is the defined folder in which R will then import and export files from and to. This allows users to send whole files to others who can replicate the work by simply changing the working directory to the new file location.

The current working directory can be found by typing:

```{r,echo=TRUE}
getwd()
```

A new working directory can be set by clicking on the tab (Session) then (Set_Working Directory), or by the command setwd:

```{r,echo=TRUE,eval=FALSE}
setwd(filename)
```

#### Downloading files from the internet

Sometimes it is more practical to download files directly from the internet. There are lots of different packages out there to do this. The one I use was developed by Hadley Wickham, called readr. Here we are going to download some data from the github page for the course.

```{r,echo=TRUE,eval=FALSE}
# load the readr package, if this is not installed then install it.
library(readr)

#use the function read_csv
data <- read_csv("https://raw.githubusercontent.com/RobertASmith/Intro_to_R/master/Data/who_complete.csv")
```

Downloading files directly to R within the same script as the analysis can be useful since it reduces the risk of you accidently changing the file. Just be careful that the data will always be available. 

### Summarising Data

### Plotting Data

### Basic Regression

### Basic Simulation
We can do much more complex calculations within loops, the sky is the limit, but here are two examples.

**Example 1**
Example 1 is an example of discounting each year simply by multiplying the previous year value by (1/(1+d.r)).

```{r echo=TRUE}

#create an vector of empty data
v.val <- vector(mode = "numeric",length = 100)

# start with 1
v.val[1] <- 1
 
# Discount our value at 1.5% each year
for(i in 2:length(v.val)) {            # for each value of i in the odds object.
  
  v.val[i] <- v.val[i-1]* (1/1.015)    # it takes the value of the previous year value 1/(1.015)

  }                                      # close the loop

plot(v.val,type="l")                           # print the vector

```

An important lesson though, it is often possible to achieve a goal without loops, which is much faster in R when running big simulations. In this case we could have achieved the same result with the following, much simpler code:

```{r echo=TRUE}

v.val <- (1/1.015)^(1:100)

plot(v.val,type = "l")

```

**Example 2**
Example 2 records the survival of 1000 individuals who die with probability 0.1 in any given year.

```{r echo=TRUE}

#create an vector of empty data
m.ind <- matrix(data = NA,
                nrow = 100,
                ncol = 1000)

# everyone starts alive (1) 
m.ind[1,] <- 1
 
# Each person has a probability of death of 0.1
for(i in 2:nrow(m.ind)) { 
  
  # value is 1 if alive in previous period and random number > 0.1 
  m.ind[i,] <- m.ind[i-1,] * runif( n = 1000, min = 0, max=1 ) > 0.1  
}                                      # close the loop

plot(rowSums(m.ind),type="l")   # print the sums of the rows of the matrix (% alive)

```

<P style="page-break-before: always">

**Example 3**

Example 3 runs a simple simulation testing the claims by the FIRE movement, Financial Independence Retire Early, that 4% is a safe withdrawl rate on a portfolio made up of US equities. 


```{r echo=FALSE,warning=FALSE,message=FALSE}

library("imager")
library(ggplot2)
library(magick)

firepic <- image_read(path = "https://raw.githubusercontent.com/RobertASmith/Intro_to_R/master/Images/Firepic.JPG")

print(firepic)
# alternatively could plot it like a graph - plot(firepic)

```

We start by clearing the work environment and loading pre-downloaded packages and the required data.

```{r echo=TRUE,warning=FALSE,message=FALSE}

#===
# FINANCIAL INDEPENDENCE RETIRE EARLY
#===

# clear the work environment
rm(list=ls())

# load necessary pre-downloaded packages
library(readxl)
library(readr)
library(fitdistrplus)

# Read in data from source, an excel file using data from https://www.macrotrends.net/2526/sp-500-historical-annual-returns

#sp500 <- as.data.frame(read_excel("Data/snp.xlsx", sheet = "Sheet1"))

sp500 <- read_csv("https://raw.githubusercontent.com/RobertASmith/Intro_to_R/master/Data/snp.csv")

```

Then we can look at real returns of the S&P500 index since 1928.

```{r echo=FALSE}

# What do returns look like since 1928
mean <- fitdist(data = sp500$`Annual Change`, 
        method = "mle", 
        distr = "norm")$`estimate`["mean"]
sd   <- fitdist(data = sp500$`Annual Change`, 
                method = "mle",
                distr = "norm")$`estimate`["sd"]


# create a simulated set of returns for the s&p500.

## check plot matches S&P500
plot(density(sp500$`Annual Change`*100),
     col="black",
     main = "Distribution of Annual Real Returns \n S&P500 1928-2018",
     xlab = "Annual Percent Change",
     xlim = c(-100,100))
text(x = 50,y=0.02,
          labels = paste("s.d", "=", round(sd*100,1)))
text(x = 8,y=0.001,
          labels = paste("mean", "=", round(mean*100,1)))

abline(v = mean*100)

```

Since the returns follow what is close to a normal distribution with a mean of approximately `r round(mean*100,2)` and a standard deviation of approximately `r round(sd*100,2)`, it is possible to create a sample of 50,000 using the **rnorm** function in R.

```{r echo=TRUE}

set.seed(100)

# create vector of returns with mean = mean and s.d  = standard deviation.
v.rrsp500 <- rnorm(n = 50000,
                   mean = mean,
                   sd = sd)
```

We can then plot these to show that the two are very similar, enough for this simple analysis anyway.

```{r echo=FALSE}
plot(density(sp500$`Annual Change`*100),
     col="black",
     main = "Distribution of Annual Real Returns \n S&P500 1928-2018",
     xlab = "Annual Percent Change",
     xlim = c(-100,100))
lines(density(v.rrsp500*100),col="red")
text(x = 50,y=0.02,
          labels = paste("s.d", "=", round(sd*100,1)))
text(x = 8,y=0.001,
          labels = paste("mean", "=", round(mean*100,1)))
abline(v = mean*100)
abline(v = mean(v.rrsp500)*100,
       col="red",
       lty=9)
legend('topleft',
       legend = c("Actual","Simulated"),
       cex=0.6,
       col=c("black","red"),
       lty = 1)

```

Then we can run a simulation to see what would happen to a £1million pound portfolio invested solely in the S&P500. We want to see what happens if a person withdraws 40,000, 4% of the original 1million, every year but keeps excess money the market may return to them invested.

```{r echo=TRUE}

# create a set of returns for 1000 people for 50 years
sim.real.returns <- matrix(data = v.rrsp500,
                           nrow = 50, 
                           ncol = 1000)

#create a results matrix, 50 years 1000 individuals
results <- matrix(data = NA,
                  nrow = 50,
                  ncol = 1000)

#create a vector to store the % with net worth >0
solvent <- vector(mode = "numeric",length = 50)

# everybody starts with £100000
results[1,] <- 1000000

# Loop for 4%

for(x in 2:50){ # loop from 2 to 50 years
  results[x,] <- (results[x-1,] - results[1,]*0.04)*(1+sim.real.returns[x,])
  solvent[x] <- sum(results[x,] >0)/1000
}
```

Since we have a sample of 1000, we can plot the probability of being solvent (not running out of money), over time. As we can see, the risk of running out of money is very low at first, but over 40 years they are quite high, close to 1/4 of the time.

```{r echo=FALSE}
plot(solvent[2:50],col="blue",type="l",
     main = "Probability of being solvent)",
     xlab = "Years from beginning withdrawl",
     ylab = "Prob solvent")
     legend(x = 40,y=1,legend =c("3%","3.5%","4%"),
            fill = c("green","red","blue"),cex=0.6)
```

We can then replicate the analysis for other rates of withdrawl and add to the graph.
For example 3.5% and 3%.

```{r echo=TRUE}

plot(solvent[2:50],col="blue",type="l",
     main = "Probability of being solvent)",
     xlab = "Years from beginning withdrawl",
     ylab = "Prob solvent")
     legend(x = 40,y=1,legend =c("3%","3.5%","4%"),
            fill = c("green","red","blue"),cex=0.6)

# Loop for 3.5% 

for(x in 2:50){
  results[x,] <- (results[x-1,] - results[1,]*0.035)*(1+sim.real.returns[x,])
  solvent[x] <- sum(results[x,] >0)/1000
}

lines(solvent[2:50],col="red")

# Loop for 3% 

for(x in 2:50){
  results[x,] <- (results[x-1,] - results[1,]*0.03)*(1+sim.real.returns[x,])
  solvent[x] <- sum(results[x,] >0)/1000
}

lines(solvent[2:50],col="green")


lines(x=c(30,30),y=c(0,1))
```

Reducing our withdrawl to 3% reduces our probability of running out of money over 30 years quite substantially. From around 18% to around 8%.

The purpose of this example was not to provide financial advice, but to show how simple this type of analysis is in R.As always there are numerous limitations with the analysis:

* The annual returns are not completely independent. The stock market has booms and busts.
* Individuals may choose to spend less in recessions, or have alternative incomes.
* Individuals will probably have more diversified portfolios.

## Where to find further Information

# Course 2

## Using R Markdown
This document has been created in R Markdown.

It is possible to embed an R-Shiny App into an R-Markdown Document.

####```{r fig.height=8, fig.width=8}
####knitr::include_app(url = "https://iolmap.shinyapps.io/parkrun/")
####```

Or just a simple website:

```{r fig.height=8, fig.width=8}
#knitr::include_url(url = "https://www.youtube.com/watch?v=KznAcOK7cTQ")

```
####<iframe src="https://www.youtube.com/watch?v=KznAcOK7cTQ" style="border: none; ####width: 900px; height: 500px"></iframe>

#### Creating an animation

It is possible to create animations in R. For public health this may be best when trying to show how a relationship between two variables changes over time, allowing a x and y axis to be displayed for each time period and moving through time periods allowing the viewer to 'see' the relationship changing.

This example allows the user to see how life expectancy and GDP per capita change over time in these countries. Using GGPlot it is also possible to see how the size of the countries change over time by changing the size of the points.

```{r,echo=TRUE,eval=FALSE}
#  install.packages("magick")

library(gapminder)
library(ggplot2)

img <- image_graph(width = 600,height = 400,res = 100)

datalist <- split(gapminder,gapminder$year)

out <- lapply(X = datalist,FUN = function(data){
          p <- ggplot(data, aes(gdpPercap, 
                                lifeExp, 
                                size = pop, 
                                color = continent)) +
                scale_size(name = "population", 
                           limits = range(gapminder$pop)) + 
                geom_point() + 
                ylim(20, 90) + 
                scale_x_log10(limits = range(gapminder$gdpPercap)) + 
                ggtitle(data$year) + 
                theme_classic()
          print(p)
          })

dev.off()

animation <- image_animate(image = img, loop = 2,fps = 2)


#image_write(image = animation, path = "C:/Users/Robert/Desktop/Rcourse/Intro_to_R/Images/gapminder.gif")

```

In my own research I have use this to show how the distribution of physical activity changes as a cohort ages from 16 to 80 years of age...



